#!/usr/bin/env python3
"""Macro Market Analyzer with Gemini AI"""
import os, json, requests, logging
import yfinance as yf
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()
load_dotenv(os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env'))
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MacroDataCollector:
    def __init__(self):
        self.tickers = {
            'VIX': '^VIX', 'DXY': 'DX-Y.NYB', '10Y_Yield': '^TNX',
            'GOLD': 'GC=F', 'OIL': 'CL=F', 'BTC': 'BTC-USD', 'SPY': 'SPY', 'QQQ': 'QQQ'
        }
    
    def get_data(self):
        logger.info("Fetching macro data...")
        data = {}
        try:
            tickers = list(self.tickers.values())
            df = yf.download(tickers, period='5d', progress=False)
            for name, ticker in self.tickers.items():
                try:
                    if ticker not in df['Close'].columns: continue
                    hist = df['Close'][ticker].dropna()
                    if len(hist) < 2: continue
                    val, prev = hist.iloc[-1], hist.iloc[-2]
                    data[name] = {'value': round(val, 2), 'change_1d': round(((val/prev)-1)*100, 2)}
                except: pass
        except Exception as e:
            logger.error(f"Error: {e}")
        return data

class MacroAIAnalyzer:
    def __init__(self):
        self.api_key = os.getenv('GOOGLE_API_KEY')
        self.url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
    
    def analyze(self, data, lang='ko'):
        if not self.api_key: return "API Key Missing"
        
        metrics = "\n".join([f"- {k}: {v['value']} ({v['change_1d']:+.1f}%)" for k,v in data.items()])
        current_date = datetime.now().strftime("%Y-%m-%d")
        
        system_instruction = f"""
        Role: **Scientific Market Historian & Quantitative Strategist**
        Current Date: {current_date}
        
        [Principle: The "Genius Questioning" Protocol]
        1. **Data-Driven Grounding:** You must cite the provided exact numbers (VIX, Yields, etc.) as evidence. Do NOT vague assertions.
        2. **Fractal Verification:** When comparing to history (e.g., 2008, 1970s), you must prove the similarity mathematically based on the provided changes. If data does not match, reject the fractal.
        3. **Adversarial Thinking:** Ask yourself "Why might my view be wrong?" before concluding.
        """
        
        if lang == 'ko':
            # Korean Specific System Instruction with Genius Protocol
            system_instruction_ko = f"""
            ì—­í• : **ê³¼í•™ì  ì‹œìž¥ ì—­ì‚¬í•™ìž ë° í€€íŠ¸ ì „ëžµê°€**
            í˜„ìž¬ ë‚ ì§œ: {current_date}
            
            [ì›ì¹™: "ì²œìž¬ë“¤ì˜ ì§ˆë¬¸ë²•" í”„ë¡œí† ì½œ]
            1. **ë°ì´í„° ê¸°ë°˜ ê·¼ê±° (Data-Driven):** ëª¨í˜¸í•œ ì£¼ìž¥ ëŒ€ì‹  ë°˜ë“œì‹œ ì œê³µëœ ì •í™•í•œ ìˆ˜ì¹˜(VIX, êµ­ì±„ê¸ˆë¦¬ ë“±)ë¥¼ ê·¼ê±°ë¡œ ì¸ìš©í•˜ì‹­ì‹œì˜¤.
            2. **í”„ëž™íƒˆ ê²€ì¦ (Fractal Verification):** ê³¼ê±°(2008ë…„, 1970ë…„ëŒ€ ë“±)ì™€ ë¹„êµí•  ë•ŒëŠ” ì œê³µëœ ë°ì´í„° ë³€í™”ìœ¨ì— ê¸°ì´ˆí•˜ì—¬ ìˆ˜í•™ì /ë…¼ë¦¬ì  ìœ ì‚¬ì„±ì„ ì¦ëª…í•˜ì‹­ì‹œì˜¤. ë°ì´í„°ê°€ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ê³¼ê°ížˆ ê¸°ê°(Reject)í•˜ì‹­ì‹œì˜¤.
            3. **ë°˜ëŒ€ ì‹¬ë¬¸ (Adversarial Thinking):** ê²°ë¡ ì„ ë‚´ë¦¬ê¸° ì „ì— ë°˜ë“œì‹œ "ë‚´ ë¶„ì„ì´ í‹€ë ¸ë‹¤ë©´ ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€?"ë¥¼ ìžë¬¸í•˜ê³  ì´ë¥¼ ëª…ì‹œí•˜ì‹­ì‹œì˜¤.
            """
            
            prompt = f"""{system_instruction_ko}
            
            [ì œê³µëœ ì‹¤ì‹œê°„ ë°ì´í„°]
            {metrics}
            
            [ë¶„ì„ ê³¼ì œ]
            1. **ðŸ” ë°ì´í„° ê²€ì¦ (Data Audit):** VIX, 10ë…„ë¬¼ êµ­ì±„, ë‹¬ëŸ¬ ì¸ë±ìŠ¤ ë“± 'í˜„ìž¬ ìˆ˜ì¹˜'ê°€ ì˜ë¯¸í•˜ëŠ” ë°”ë¥¼ ì§ì„¤ì ìœ¼ë¡œ í•´ì„í•˜ì‹­ì‹œì˜¤. (ì˜ˆ: VIX 13 ì´í•˜ëŠ” ì•ˆë„ê°ì¸ê°€, í­í’ì „ì•¼ì¸ê°€?)
            2. **ðŸ“œ í”„ëž™íƒˆ ê²€ì¦ (Fractal Verify):** "ì§€í‘œ íŒ¨í„´"ì— ê¸°ë°˜í•˜ì—¬ ê³¼ê±°(1970s, 2000, 2022 ë“±)ì™€ ê°€ìž¥ ìœ ì‚¬í•œ êµ­ë©´ì„ ì°¾ìœ¼ì‹­ì‹œì˜¤. 
               - *ì£¼ì˜:* ë‹¨ìˆœížˆ ëŠë‚Œìœ¼ë¡œ ë¹„êµí•˜ì§€ ë§ê³ , "ê¸ˆë¦¬ê°€ ì˜¤ë¥´ëŠ”ë° ë‚˜ìŠ¤ë‹¥ì´ ì˜¤ë¥´ëŠ” í˜„ìƒ" ë“± êµ¬ì²´ì  ìƒê´€ê´€ê³„ë¡œ ì¦ëª…í•˜ì‹­ì‹œì˜¤. ìœ ì‚¬í•œ ê³¼ê±°ê°€ ì—†ë‹¤ë©´ ì—†ë‹¤ê³  ë§í•˜ì‹­ì‹œì˜¤.
            3. **âš¡ ìœ ë™ì„± ë° í•µì‹¬ ë³€ìˆ˜:** ì§€ê¸ˆ ì‹œìž¥ì´ ìƒìŠ¹/í•˜ë½í•˜ëŠ” ë‹¨ í•˜ë‚˜ì˜ 'Money Flow' ì›ì¸ì€ ë¬´ì—‡ìž…ë‹ˆê¹Œ? ìœ ë™ì„±ì´ ì–´ë””ë¡œ íë¥´ê³  ìžˆìŠµë‹ˆê¹Œ?
            4. **ðŸ”® ê²°ë¡  (Scenario):** ìœ„ ë¶„ì„ì„ í† ëŒ€ë¡œ í–¥í›„ 1ì£¼~1ê°œì›” ì‹œìž¥ì˜ êµ¬ì²´ì  ë°©í–¥ì„±(Strong Buy / Watch / Sell)ì„ ì œì‹œí•˜ì‹­ì‹œì˜¤.
            
            í˜•ì‹: ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸, ëª…í™•í•œ ë…¼ê±° í•„ìˆ˜. ë‹µë³€ì€ 100% í•œêµ­ì–´ë¡œ ìž‘ì„±í•˜ì‹­ì‹œì˜¤.
            """
        else:
            prompt = f"""{system_instruction}
            
            [Real-time Data]
            {metrics}
            
            [Analysis Task]
            1. **Data Audit:** Interpret the exact numbers provided. What does the current VIX/Yield combination scream?
            2. **Fractal Verification:** Mathematically compare current correlations to historical regimes (1970s, 2000s). Prove the match using the provided data points.
            3. **Liquidity Driver:** Where is the money flowing? Identify the single most critical variable driving today's price action.
            4. **Verdict:** Provide a concrete 1-month forecast based on this evidence.
            
            Format: Markdown, strict evidence-based reasoning.
            """
        
        try:
            resp = requests.post(f"{self.url}?key={self.api_key}", 
                json={"contents": [{"parts": [{"text": prompt}]}]}, timeout=30)
            if resp.status_code == 200:
                return resp.json()['candidates'][0]['content']['parts'][0]['text']
        except Exception as e:
            logger.error(f"AI Req Error: {e}")
            pass
        return "AI Analysis failed."

class MultiModelAnalyzer:
    def __init__(self, data_dir=None):
        if data_dir is None:
            data_dir = os.getenv('DATA_DIR', os.path.join(os.path.dirname(__file__), '..', 'data'))
        self.data_dir = data_dir
        os.makedirs(self.data_dir, exist_ok=True)
        self.collector = MacroDataCollector()
        self.gemini = MacroAIAnalyzer()
    
    def run(self):
        data = self.collector.get_data()
        analysis_ko = self.gemini.analyze(data, 'ko')
        analysis_en = self.gemini.analyze(data, 'en')
        
        output = {'timestamp': datetime.now().isoformat(), 'indicators': data, 'analysis_ko': analysis_ko, 'analysis_en': analysis_en}
        with open(os.path.join(self.data_dir, 'macro_analysis.json'), 'w') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
        logger.info("Saved macro analysis")
        return output

if __name__ == "__main__":
    MultiModelAnalyzer().run()
